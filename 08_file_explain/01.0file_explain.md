📌 **השלב הראשון – הבנת הדאטהסט**

### 🔹 הסבר פשוט (כמו לילד קטן)

תאר לך שעשו ניסוי שבו אנשים ניסו לעצור תנועה לפי צליל או לפי קצב. 

בכל פעם שמישהו עשה ניסיון (מה שנקרא "trial"), נמדדו כמה דברים:

🔸 כמה רחוק הם זזו

🔸 כמה חזק הם לחצו

🔸 כמה זמן לקח להם לעצור

🔸 כמה זמן לקח להם להגיב

🔸 כמה הם טעו בקצב

🔸 ואפילו – איזה סוג של ניסוי זה היה (למשל, תזמון עצמאי או מבוסס קול)

כמו יומן של כל ניסיון כזה, נשמר קובץ – שבו כל שורה היא ניסיון אחד, ובשורה הזו יש מספרים שמייצגים את כל מה שנמדד.

---

### 🔹 הסבר מקצועי יותר

קובץ ה־CSV שהעלית נקרא:

```
The_role_of_consciously_timed_movements_in_shaping_and_improving_auditory_timing_(All_Subject_Data).csv
```

והוא כולל נתונים מניסוי מחקרי על **השפעת תנועה מתוזמנת על שגיאות בתזמון שמיעתי**.

🔸 **כל שורה** = ניסיון של נבדק אחד

🔸 **העמודות החשובות ביותר:**

| שם עמודה      | הסבר                                                                   |
| ------------- | ---------------------------------------------------------------------- |
| `movdist`     | מרחק תנועה – כמה רחוק היד או הגוף זזו בניסיון הזה                      |
| `force`       | כוח הלחיצה או התנועה שנמדדה                                            |
| `stoplatency` | כמה זמן לקח לעצור אחרי גירוי שמיעתי                                    |
| `repduration` | זמן שלקח לתגובה כולה (מהתחלה עד הסוף)                                  |
| `error`       | השגיאה בתזמון – כמה מוקדם או מאוחר מהצליל הנכון האדם פעל               |
| `abserror`    | השגיאה המוחלטת – כמו `error` רק בלי שליליים (כמה טעינו בלי קשר לכיוון) |
| `trialtype`   | סוג הניסוי – לדוגמה, תזמון פנימי לעומת חיצוני                          |

💡 כל העמודות המספריות נמדדות ביחידות זמן/מרחק/כוח וניתנות לניתוח סטטיסטי.


📌 **הבנת מבנה הקובץ**

### 🔹 הסבר פשוט
בקובץ הזה יש 4,070 שורות – כל שורה זה ניסיון של בן אדם בניסוי.

יש 9 עמודות שונות – כל אחת מספרת משהו אחר על אותו ניסיון.

נחשוב על זה כמו דוח של מבחן: כל תלמיד (נבדק) ניסה לעצור תנועה לפי צליל או לפי קצב – ומישהו רשם עליו דברים כמו:

🔸 מה מספר הנבדק

🔸 איזה סוג ניסוי הוא עשה

🔸 כמה זמן לקח לו להגיב

🔸 כמה רחוק הוא זז

🔸 האם הוא הקדים או איחר

---

### 🔹 הסבר מקצועי

| 🧠 עמודה      | 🧾 תיאור                                                                           | 📏 סוג הנתון          |
| ------------- | ---------------------------------------------------------------------------------- | --------------------- |
| `subject`     | מזהה ייחודי לנבדק (מספר משתתף)                                                     | מספר שלם `int64`      |
| `trialtype`   | סוג הניסוי – לדוגמה: **Self-Paced** (תזמון פנימי) או **Cue-Based** (תזמון לפי רמז) | טקסט `object`         |
| `duration`    | משך כולל של הניסיון (לא בשימוש ישיר בקוד, אבל קיים)                                | מספר שלם `int64`      |
| `repduration` | זמן שלקח לביצוע התגובה (מהתחלה ועד הסוף)                                           | מספר שלם `int64`      |
| `movdist`     | מרחק התנועה – כמה רחוק האדם זז                                                     | מספר עשרוני `float64` |
| `force`       | כוח – מדד לכמה חזק הייתה התנועה                                                    | מספר עשרוני `float64` |
| `stoplatency` | זמן עד עצירה לאחר הצליל                                                            | מספר שלם `int64`      |
| `error`       | השגיאה בתזמון (שלילי אם הקדים, חיובי אם איחר)                                      | מספר שלם `int64`      |
| `abserror`    | השגיאה המוחלטת – תמיד חיובית                                                       | מספר שלם `int64`      |

---

✔️ **אין שום ערך חסר** – כל התאים מלאים לחלוטין.
💡 זה מאפשר לנו לנתח בלי לפחד מחורים בדאטה.


📌 **סקירה של הפונקציות בקוד**

### 🔹 פונקציות בדיקה (Validation)

| 🧠 שם הפונקציה            | 📝 תיאור קצר                                       | 🎯 מטרה                         |
| ------------------------- | -------------------------------------------------- | ------------------------------- |
| `no_missing_columns(df)`  | בודקת אם כל העמודות הדרושות קיימות בקובץ           | למנוע ניתוחים על דאטה חסר       |
| `no_data_missmatches(df)` | בודקת שכל הערכים המספריים באמת מספריים             | מוודאת שהדאטה קריא לעיבוד מתמטי |
| `no_missing_values(df)`   | בודקת אם יש יותר מ־30% ערכים חסרים בעמודות קריטיות | להבטיח אמינות הדאטה             |
| `is_valid_df(df)`         | מרכזת את שלוש הבדיקות הקודמות לבדיקה אחת כוללת     | תנאי סף להמשך עיבוד             |

---

### 🔹 פונקציית ניקוי (Cleaning)

| 🧠 שם הפונקציה   | 📝 תיאור קצר                                               | 🎯 מטרה                         |
| ---------------- | ---------------------------------------------------------- | ------------------------------- |
| `clean_data(df)` | מנקה את הדאטה: משלימה ערכים חסרים ומסירה חריגים (outliers) | לאפשר ניתוח תקין ובלי רעש מיותר |

---

### 🔹 פונקציות ויזואליזציה (Visualizations)

| 🧠 שם הפונקציה                                        | 📝 תיאור קצר                                                  | 🎯 מטרה                             |
| ----------------------------------------------------- | ------------------------------------------------------------- | ----------------------------------- |
| `create_plots(df, mov_var, err_var)`                  | מציירת 3 גרפים: פיזור, boxplot, היסטוגרמה עבור משתנים מסוימים | להבין חזותית קשר בין תנועה לשגיאה   |
| `analyze_response_time_impact(df, significant_pairs)` | מציירת גרפים תלת־ממדיים לפי צבע שמראה משך תגובה               | להבין האם משך תגובה משפיע על השגיאה |

---

### 🔹 פונקציות ניתוח (Analysis)

| 🧠 שם הפונקציה                          | 📝 תיאור קצר                                               | 🎯 מטרה                              |
| --------------------------------------- | ---------------------------------------------------------- | ------------------------------------ |
| `get_correlation(df, mov_var, err_var)` | מחשבת מתאם פיירסון בין משתנה תנועה לשגיאה                  | לזהות קשרים סטטיסטיים ישירים         |
| `analyze_relationships(df)`             | מריצה את הפונקציות הקודמות על כל סוג ניסוי וכל משתנה תנועה | מפיקה את הקורלציות המלאות בין משתנים |

---

### 🔹 פונקציה ראשית (Main)

| 🧠 שם הפונקציה    | 📝 תיאור קצר                                                    | 🎯 מטרה                       |
| ----------------- | --------------------------------------------------------------- | ----------------------------- |
| `main(data_path)` | מנהלת את כל התהליך מקצה לקצה: קריאה, בדיקה, ניקוי, ניתוח, גרפים | להפעיל את כל המחקר בלחיצה אחת |

---

💡 **סדר פעולת הקוד כולו:**

1. קרא את הקובץ
2. בדוק שהוא תקין
3. נקה את הדאטה
4. צור גרפים
5. חשב מתאמים
6. אם יש קשרים משמעותיים (p < 0.05) – בדוק השפעה של משך תגובה
7. הצג את הממצאים


📂 פתיחת הקובץ main.py

🔹 שורות 1–5: טעינת ספריות 📚
```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats
import numpy as np
````

🧒 הסבר פשוט:

כמו שאתה מביא כלים כדי לבנות משהו, גם פייתון צריך כלים כדי לעבוד על דאטה, לצייר גרפים ולחשב סטטיסטיקות. אז כאן אנחנו מכניסים את כל ארגז הכלים הדרושים:

🔸 pandas – לטיפול בטבלאות
🔸 seaborn ו־matplotlib.pyplot – לציור גרפים
🔸 scipy.stats – לחישובים סטטיסטיים (כמו מתאם)
🔸 numpy – לעבודה עם מספרים ופעולות מתמטיות

🎓 הסבר מקצועי:

ייבוא של חמש ספריות חיוניות לעבודה עם דאטה:

pandas – קריאה, ניקוי וניתוח DataFrame

seaborn – גרפים סטטיסטיים מתקדמים

matplotlib.pyplot – שליטה נמוכה יותר בגרפים

scipy.stats – חישוב מתאם פיירסון

numpy – חישובי מדדים ומילוי ערכים



---

🔹 שורה 7: הגדרת הנתיב של הקובץ

```python
DATA_PATH = 'The_role_of_consciously_timed_movements_in_shaping_and_improving_auditory_timing_(All_Subject_Data).csv'
````

🧒 הסבר פשוט:

אמרנו לתוכנה: "הקובץ עם הנתונים שאתה צריך נמצא פה".

🎓 הסבר מקצועי:

יצירת משתנה DATA_PATH עם מחרוזת המציינת את שם הקובץ שממנו ייקרא ה־DataFrame. ישמש בהמשך ב־pd.read_csv.


---

🔹 שורה 9–17: מילון שמתרגם שמות משתנים

```python
VARS_TO_PRINT = {
    'movdist': 'Movement Distance',
    'force': 'Force',
    'stoplatency': 'Stop Latency',
    'repduration': 'Response Duration',
    'error': 'Error',
    'abserror': 'Absolute Error',
    'trialtype': 'Trial Type',
}
````

🧒 הסבר פשוט:

זה כמו רשימת שמות יפים שמשתמשים בהם בכותרות הגרפים. במקום להראות שמות קשים כמו movdist, אנחנו נשתמש בשם נעים כמו "מרחק תנועה".

🎓 הסבר מקצועי:

מילון שממפה בין שמות משתנים בגוף הדאטה לשמות קריאים יותר עבור כותרות גרפים. כך למשל 'movdist' יוצג כ־"Movement Distance".


---

🔹 הפונקציה הראשונה – no_missing_columns
```python
def no_missing_columns(df):
    """
    Check if the dataframe contains the required columns
    """
    required_columns = ['movdist', 'force', 'stoplatency', 'repduration', 'error', 'abserror', 'trialtype']
    missing_columns = [col for col in required_columns if col not in df.columns]
    return len(missing_columns)==0
````

🧒 הסבר פשוט:

פה אנחנו בודקים: "האם כל מה שאנחנו צריכים נמצא בטבלה?".
אם חסר עמודה חשובה – נגיד שזה לא תקין.

🎓 הסבר מקצועי:

הפונקציה מקבלת DataFrame ובודקת האם כל העמודות החיוניות קיימות בו. היא מחזירה True אם לא חסר כלום, ו־False אם חסר לפחות עמודה אחת.


🧠 no_missing_values(df)
```python
def no_missing_values(df):
    """
    Check if any column contains missing values more than 30%
    """
    for col in ['movdist', 'force', 'stoplatency', 'repduration', 'error', 'abserror']:
        if df[col].isnull().sum()>0.3*len(df[col]):
            return False
    return True
````
🔹 הסבר פשוט

אנחנו שואלים: "האם יש עמודה עם המון תאים ריקים?"
אם יותר מ־30% חסרים – נגיד שזה גרוע מדי כדי לעבוד עם זה.

🎓 הסבר מקצועי

הפונקציה בודקת האם יש בעמודות המרכזיות יותר מ־30% ערכים חסרים (NaN).

אם יש כזו עמודה – היא מחזירה False, אחרת True.

רף ה־30% מבוסס על מדיניות סינון של מידע בעייתי מדי.



---

🧠 is_valid_df(df)
```python
def is_valid_df(df):
    """
    Check if the dataframe is valid
    """
    return no_missing_columns(df) and no_data_missmatches(df) and no_missing_values(df)
````

🔹 הסבר פשוט

פה אנחנו שואלים:
"האם הקובץ שלנו באמת תקין?"
והתשובה תהיה כן רק אם: ✔️ יש בו את כל העמודות
✔️ כל המספרים תקינים
✔️ אין בו יותר מדי ערכים חסרים

🎓 הסבר מקצועי

זו פונקציית מעטפת (wrapper) שמרכזת את שלוש בדיקות האיכות שראינו קודם:

עמודות קיימות

סוגי נתונים תקינים

אין ערכים חסרים ברמה קריטית


💡 אם אחד מהם נכשל – is_valid_df תחזיר False והקוד יפסיק לרוץ.


---

🧹 clean_data(df)
```python
def clean_data(df):
    """
    Clean the dataset by handling missing values and removing outliers
    """
    # Create a copy of the dataframe
    df_clean = df.copy()
````

🔹 הסבר פשוט

כמו לקחת דף עקום ומלוכלך, ולעשות ממנו דף חדש ונקי.
השלב הראשון – עושים העתק של הטבלה המקורית כדי לא להרוס אותה.

🎓 הסבר מקצועי

יוצרים עותק (copy) של ה־DataFrame כדי לעבוד עליו בלי לשנות את המקור – עיקרון חשוב בתהליכי עיבוד נתונים.


---
```python
# 1. Handle missing values
    # Fill missing values with median for numeric columns
    numeric_columns = df_clean.select_dtypes(include=[np.number]).columns
    for col in numeric_columns:
        df_clean[col] = df_clean[col].fillna(df_clean[col].median())
````

🔹 הסבר פשוט

אם בטעות חסר מספר בתא כלשהו – אנחנו ממלאים אותו בערך האמצעי (החציוני) של אותה עמודה.
למה? כי הוא לא הכי גדול ולא הכי קטן – הוא "באמצע".

🎓 הסבר מקצועי

select_dtypes(include=[np.number]) שולף רק את העמודות המספריות.

fillna(...median()) ממלא ערכים חסרים בערך החציוני – פתרון עמיד נגד outliers קיצוניים.



---
```python
# Fill missing values in categorical columns with mode
    categorical_columns = df_clean.select_dtypes(include=['object']).columns
    for col in categorical_columns:
        if col != 'trialtype':  # Specifically check for non-numeric categories
            df_clean[col] = df_clean[col].fillna(df_clean[col].mode()[0])
````

🔹 הסבר פשוט

אם יש עמודות טקסט עם ערכים חסרים – אנחנו משלימים אותן עם הערך שהופיע הכי הרבה פעמים (מצב – mode).

🎓 הסבר מקצועי

שליפה של עמודות טקסטואליות (object)

מילוי ערכים חסרים בעזרת mode()[0] – הערך הנפוץ ביותר

יש התעלמות מ־trialtype כאן (ייתכן בטעות – אין צורך בהתניה הזו בקובץ הנוכחי כי trialtype לא חסר)



---
```python
# 2. Remove outliers using IQR method
    for col in ['movdist', 'force', 'stoplatency', 'repduration', 'error', 'abserror']:
        if col in df_clean.columns:
            # Calculate Q1, Q3, and IQR
            Q1 = df_clean[col].quantile(0.25)
            Q3 = df_clean[col].quantile(0.75)
            IQR = Q3 - Q1
            # Define bounds
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            # Remove outliers
            df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]
````

🔹 הסבר פשוט

אנחנו מנקים ערכים קיצוניים מהטבלה – כאלה שממש חריגים לעומת השאר.
למשל אם כולם זזו 30–60 ס"מ, אבל מישהו עשה 300 – נזרוק אותו.

🎓 הסבר מקצועי

שימוש בשיטת IQR (interquartile range) לסינון outliers:

מחשבים רבעון ראשון (Q1), רבעון שלישי (Q3)

מחשבים את תחום ה־IQR = Q3 - Q1

מסירים ערכים שנמצאים מחוץ לטווח:
[Q1 - 1.5*IQR, Q3 + 1.5*IQR]




---
```python
# Print cleaning summary
    print("Data Cleaning Summary:")
    print(f"Original rows: {len(df)}")
    print(f"Rows after cleaning: {len(df_clean)}")
    print(f"Removed rows: {len(df) - len(df_clean)}")
    return df_clean
````

🔹 הסבר פשוט

מדפיסים כמה שורות היו לפני הניקוי, כמה נשארו – וכמה שורות נמחקו (חריגות או חסרות).

🎓 הסבר מקצועי

שלב הדיווח הסופי של הפונקציה – נוח ל־debug ולבדיקת איכות הניקוי.
לבסוף הפונקציה מחזירה את הדאטה לאחר הניקוי כ־df_clean.


📊 create_plots(df, mov_var, err_var)
```python
def create_plots(df, mov_var, err_var):
    """
    Create plots to visualize relationships between movement parameters and errors
    """
````

🔹 הסבר פשוט

המטרה כאן היא לצייר גרפים כדי לראות אם יש קשר בין:

תכונת תנועה (כמו מרחק או כוח)

לבין השגיאה שנוצרה בתזמון.


אנחנו נותנים לפונקציה שני משתנים:

משתנה תנועה (כמו movdist)

משתנה שגיאה (כמו error)


והיא תצייר לנו שלושה סוגי גרפים לכל זוג כזה.


---

🎓 הסבר מקצועי

הפונקציה מקבלת:

df: טבלת הנתונים

mov_var: משתנה תנועה (x)

err_var: משתנה שגיאה (y)


היא תבצע 3 הדמיות שונות לפי סוגי הניסויים הקיימים (trialtype), כדי להדגים קשרים אפשריים בין המשתנים.


---

🔸 שלב ראשון – בדיקות תקינות
```python
if mov_var not in df.columns or err_var not in df.columns:
        print(f"One of the specified variables '{mov_var}' or '{err_var}' is not present in the DataFrame.")
        return
    if df.empty:
        print("The DataFrame is empty. Plotting cannot be performed.")
        return
````

🧒 הסבר פשוט:

בודקים:

האם העמודות שאנחנו מבקשים לצייר – באמת קיימות?

האם בכלל יש שורות בטבלה?


אם לא – מדפיסים הודעת שגיאה ויוצאים.

🎓 הסבר מקצועי:

אימות קלט לפונקציה. אם המשתנים לא קיימים או הדאטה ריק, הפונקציה לא ממשיכה.


---

🔸 שלב שני – גרף פיזור + קו מגמה לכל סוג ניסוי
```python
fig, axes = plt.subplots(1, 2, figsize=(15, 3))
    sns.scatterplot(data=df, x=mov_var, y=err_var, hue='trialtype', ax=axes[0])
    for trial in df['trialtype'].unique():
        trial_data = df[df['trialtype'] == trial]
        sns.regplot(data=trial_data, x=mov_var, y=err_var, scatter=False, ax=axes[0])
    axes[0].set_xlabel(VARS_TO_PRINT[mov_var])
    axes[0].set_ylabel(VARS_TO_PRINT[err_var])
    axes[0].set_title(f'{VARS_TO_PRINT[mov_var]} vs {VARS_TO_PRINT[err_var]} by Trial Type')
    axes[0].legend(title=None)
````

🧒 הסבר פשוט:

פה אנחנו מציירים נקודות צבעוניות – כל נקודה זה ניסיון אחד.
אנחנו מציירים קו שמראה מה הכיוון הכללי – האם ככל שהמרחק גדל, השגיאה גדלה?

🎓 הסבר מקצועי:

scatterplot – גרף פיזור עם צבעים לפי trialtype.

regplot – קו מגמה לכל סוג ניסוי בנפרד.

שמות הצירים והכותרת נלקחים מהמילון VARS_TO_PRINT (כדי שיהיה ברור יותר בגרף).



---

🔸 שלב שלישי – Boxplot לפי סוג ניסוי
```python
sns.boxplot(data=df, x='trialtype', y=err_var, hue='trialtype', ax=axes[1])
    axes[1].set_xlabel(VARS_TO_PRINT['trialtype'])
    axes[1].set_ylabel(VARS_TO_PRINT[err_var])
    axes[1].set_title(f'{VARS_TO_PRINT[err_var]} by Trial Type')
    plt.show()
````

🧒 הסבר פשוט:

עכשיו אנחנו מציירים קופסה לכל סוג ניסוי – כדי לראות איך השגיאות משתנות בין סוגים.
הקופסה מראה את רוב הערכים, והנקודות הקיצוניות יוצאות מחוץ לה.

🎓 הסבר מקצועי:

Boxplot לפי trialtype עבור משתנה השגיאה שנבחר

נועד להמחיש שונות סטטיסטית בין הקבוצות

מוצג בגרף השני מתוך שניים



---

🔸 שלב רביעי – Histogram של משתנה התנועה בכל סוג ניסוי
```python
trial_types = df['trialtype'].unique()
    fig, axes = plt.subplots(1, len(trial_types), figsize=(15, 3), constrained_layout=True)
    fig.suptitle(f'{VARS_TO_PRINT[mov_var]} by Trial Type', y=1.05)
    if len(trial_types) == 1:
        axes = [axes]
    for i, trial in enumerate(trial_types):
        trial_data = df[df['trialtype'] == trial]
        sns.histplot(data=trial_data, x=mov_var, ax=axes[i])
        axes[i].set_title(f'{trial}')
        axes[i].set_ylabel(VARS_TO_PRINT[err_var]+' Index')
    plt.show()
    return True
````

🧒 הסבר פשוט:

לכל סוג ניסוי – אנחנו מציירים עמודות שמראות באילו ערכים של תנועה השתמשו הכי הרבה.
זה עוזר לנו לראות אם יש פיזור או ריכוז.

🎓 הסבר מקצועי:

ציור היסטוגרמה נפרדת לכל trialtype

מחלק את המשתנה mov_var לבאקטים ומצייר צפיפות

עוזר לראות התפלגות משתנה התנועה



🧮 get_correlation(df, mov_var, err_var)
```python
def get_correlation(df, mov_var, err_var):
    """
    Compute Pearson correlation
    """
    if df.empty:
        print("The DataFrame is empty. Correlation cannot be computed.")
        return (np.nan, np.nan)
    return stats.pearsonr(df[mov_var], df[err_var])
````

🔹 הסבר פשוט:

אנחנו רוצים לבדוק: האם יש קשר בין תנועה לשגיאה?
לדוגמה – האם כשמישהו זז רחוק יותר, הוא גם טועה יותר?

אנחנו עושים את זה עם מדד מתמטי שנקרא "מתאם פיירסון" – הוא נותן מספר בין −1 ל־1:

1 = קשר חזק חיובי

0 = אין קשר

−1 = קשר הפוך


🎓 הסבר מקצועי:

בודקת אם ה־DataFrame ריק.

אם לא – מחזירה את ערך המתאם הסטטיסטי r ואת ה־p-value בהתבסס על scipy.stats.pearsonr.

השיטה הזו מניחה התפלגות נורמלית של המשתנים.



---

🧠 analyze_relationships(df)
```python
def analyze_relationships(df):
    """
    Analyze relationships between movement parameters and errors across trial types
    """
    # List of comparisons to make
    movement_vars = ['movdist', 'force', 'stoplatency']
    error_vars = ['error']
````

🔹 הסבר פשוט:

פה אנחנו אומרים לקוד: "תעבור על כל המשתנים של תנועה מול שגיאה, ותבדוק אם יש ביניהם קשר בכל סוג ניסוי."

🎓 הסבר מקצועי:

הפונקציה מגדירה שלושה משתני תנועה לבחינה מול משתנה שגיאה אחד (error)

נועדה לבצע השוואה בין כל זוג כזה עבור כל trialtype



---
```python
results = {}

    if df.empty:
        print("The DataFrame is empty. No relationships to analyze.")
        return results
````

🔹 הסבר פשוט:

פותחים מילון ריק שישמור את התוצאות. אם אין דאטה – מדפיסים הודעה ולא ממשיכים.

🎓 הסבר מקצועי:

results: מילון שבו יישמרו תוצאות הקורלציות

בדיקה אם הדאטה ריק היא תכונת הגנה סטנדרטית



---
```python
for mov_var in movement_vars:
        for err_var in error_vars:
            if create_plots(df, mov_var, err_var):
                for trial in df['trialtype'].unique():
                    trial_data = df[df['trialtype'] == trial]
                    correlation = get_correlation(trial_data, mov_var, err_var)
                    results[f'{mov_var}_{err_var}_{trial}'] = {
                        'correlation': correlation[0],
                        'p_value': correlation[1]
                    }
    return results
````

🔹 הסבר פשוט:

לכל שילוב של תנועה ושגיאה – מציירים גרפים

ואז בודקים קשר סטטיסטי בכל סוג ניסוי

שומרים את הקשר וה־p-value בתוך מילון לפי שם השילוב


🎓 הסבר מקצועי:

ריצה בלולאה על כל זוגות משתנים

עבור כל trialtype, נבנה תת־DataFrame ונחשב מתאם

כל תוצאה נשמרת בשם כמו movdist_error_CueBased



---

🌈 analyze_response_time_impact(df, significant_pairs)
```python
def analyze_response_time_impact(df, significant_pairs):
    """
    Analyze how response duration affects significant relationships (improved visualization)
    """
    if df.empty:
        print("The DataFrame is empty. Analysis cannot be performed.")
        return
````

🔹 הסבר פשוט:

אחרי שמצאנו קשרים משמעותיים – בודקים אם זמן התגובה משפיע עליהם.
אנחנו מציירים גרף פיזור שבו הצבעים מראים את זמן התגובה. יותר כהה = תגובה ארוכה יותר.

🎓 הסבר מקצועי:

הפרמטר significant_pairs הוא רשימת שמות משתנים שה־p-value שלהם קטן מ־0.05

הפונקציה מציירת scatter plot עם צביעה לפי repduration – למעקב חזותי אחרי השפעת משתנה שלישי



---
```python
for pair in significant_pairs:
        mov_var, err_var, trial_type = pair.split('_')
        trial_data = df[df['trialtype'] == trial_type]
        plt.figure(figsize=(12, 8))
        scatter = plt.scatter(
            trial_data[mov_var],
            trial_data[err_var],
            c=trial_data['repduration'],
            cmap='viridis',
            s=50,
            alpha=0.7,
            edgecolor='k'
        )
        plt.colorbar(scatter, label='Response Duration')
        plt.xlabel(VARS_TO_PRINT[mov_var])
        plt.ylabel(VARS_TO_PRINT[err_var])
        plt.title(f'{VARS_TO_PRINT[mov_var]} vs {VARS_TO_PRINT[err_var]} (colored by Response Duration)\nTrial Type: {trial_type}')
        plt.grid(True, linestyle='--', alpha=0.6)
        plt.tight_layout()
        plt.show()
    return True
````
🔹 הסבר פשוט:

עבור כל זוג משמעותי – מציירים נקודות לפי תנועה ושגיאה

הצבע של כל נקודה מייצג כמה זמן לקחה התגובה


🎓 הסבר מקצועי:

שימוש ב־plt.scatter עם פרמטר c=repduration

הצבע ממופה ל־cmap בשם viridis

ה־colorbar מוצג בצד כדי להסביר את פירוש הצבע



---

🚀 main(data_path)
```python
def main(data_path):
    """
    Run full analysis process
    """
    try:
        df = pd.read_csv(data_path)
        if not is_valid_df(df):
            print("No data found in the CSV file.")
            return
````

🔹 הסבר פשוט:

קוראים את הקובץ

בודקים אם הוא תקין


🎓 הסבר מקצועי:

קריאה ל־read_csv

שימוש ב־is_valid_df() כבדיקת שער



---
```python
df_clean = clean_data(df)
        results = analyze_relationships(df_clean)
        significant_pairs = [pair for pair, res in results.items() if res['p_value'] < 0.05]
        analyze_response_time_impact(df_clean, significant_pairs)
        return results
````

🔹 הסבר פשוט:

מנקים את הדאטה

מנתחים קשרים בין משתנים

שומרים רק את אלו שה־p-value שלהם מראה קשר מובהק (מתחת ל־0.05)

מציירים גרף שמראה אם זמן תגובה השפיע עליהם


🎓 הסבר מקצועי:

שלב קריאה → ניקוי → ניתוח → סינון → ויזואליזציה

הפונקציה מחזירה את כל המתאמים



---
```python
except FileNotFoundError:
        print(f"File not found: {data_path}")
        return
    except pd.errors.EmptyDataError:
        print("No data found in the CSV file.")
        return
    except pd.errors.ParserError:
        print("Error parsing the CSV file. Please check the file format.")
        return
    except ValueError as ve:
        print(f"ValueError occurred: {ve}")
        return
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        return

main(DATA_PATH)
````

🔹 הסבר פשוט:

אם קורה משהו רע – כמו שהקובץ לא נמצא או שהוא ריק – אנחנו מדפיסים הודעה ברורה.

🎓 הסבר מקצועי:

טיפול בכל חריגות אפשריות עם try-except

טיפול בחריגות ייעודיות (כמו FileNotFoundError) וגם כללי (Exception)



📌 השלב הבא – ניתוח פקודות ספציפיות
נעבור על כל פקודה, פונקציה או שורת קוד, אפילו ברמת פקודות כמו df.copy() או sns.histplot(...), ונבין בדיוק מה היא עושה – כולל רקע מתמטי, התנהגות פנימית של הספרייה, למה בחרו בה, ומה היה קורה אם היינו עושים אחרת.


---

💡 נתחיל עכשיו מפרטים שטרם הסברנו לעומק – כל פקודה שמופיעה שוב ושוב בקוד:

🔹 ניתוח פקודות חשובות בשימוש חוזר


---
```python
🧱 df.copy()
````
מה זה עושה בפועל?

יוצר עותק עצמאי של הטבלה – כלומר אם תשנה את df_clean, זה לא ישנה את df המקורי.

למה זה חשוב?

אם היית כותב df_clean = df – כל שינוי על df_clean היה משפיע גם על df, כי הם היו מפנים לאותו אובייקט בזיכרון.

דוגמה להבדל:
```python
a = [1, 2, 3]
b = a       # שינוי ב־b ישפיע גם על a
c = a.copy()  # שינוי ב־c לא ישפיע על a
````


---
```python
🧮 fillna(...)
````

מה זה?

ממלא ערכים חסרים (NaN) בערך שנבחר:
```python
fillna(0) – ממלא ב־0

fillna(df[col].median()) – ממלא בערך החציוני של העמודה
````


למה median?

החציון לא מושפע מחריגים (outliers) כמו הממוצע.

לדוגמה: אם יש לך [1, 2, 3, 4, 1000] – החציון הוא 3, אבל הממוצע מעל 200.



---
```python
🔍 df[col].isnull().sum()
````

מה זה?
```python
isnull() מחזיר סדרה של True/False לפי האם יש NaN

sum() סופר כמה פעמים קיבלנו True – כלומר כמה ערכים חסרים בעמודה
````



---
```python
📈 sns.scatterplot(...)
````

מה זה?

מצייר נקודות לפי שני משתנים (x ו־y)
```python
hue='trialtype' – מחלק את הנקודות לפי צבעים שונים לכל סוג ניסוי
````


תוצאה:

גרף צבעוני שמאפשר לראות האם תבניות משתנות בין סוגי ניסויים


---
```python
🔁 for col in df.columns:
````

מה זה עושה?

עובר על כל שמות העמודות בדאטה. אפשר לבצע לולאות דינמיות לפי שמות.


---
```python
📏 quantile(0.25) ו־quantile(0.75)
````

מה זה?

אלו הם רבעון תחתון (Q1) ורבעון עליון (Q3)

ביחד הם יוצרים את תחום ה־IQR (Interquartile Range) – שהוא מדד לפיזור ללא השפעה של חריגים



---
```python
📊 plt.scatter(...)
````

מה עושה שונה מ־sns.scatterplot?
```python
plt.scatter מגיעה מספריית matplotlib – נותנת יותר שליטה (כמו צבע לפי ערך)

c=... מאפשר צביעה לפי משתנה שלישי

edgecolor='k' = מסגרת שחורה לנקודות
````



---
```python
🧪 stats.pearsonr(x, y)
````

מה זה?

מחזיר שני ערכים:
```python
r: ערך המתאם

p: ערך המובהקות (כמה סביר שהקשר הזה לא מקרי)
````



תנאים ל־Pearson:

המשתנים רציפים

התפלגות נורמלית (בערך)

קשר ליניארי

```python
📌 plt.subplots(1, 2, figsize=(15, 3))
````
🔹 הסבר פשוט:

אנחנו מבקשים מראש ליצור שני גרפים זה ליד זה.

🎓 הסבר מקצועי:

1, 2 = שורה אחת, שתי עמודות (כלומר: שני גרפים בשורה אחת)
```python
figsize=(15, 3) = גודל כולל של התמונה – רוחב 15 אינץ’, גובה 3 אינץ’
````

מחזיר שני אובייקטים:

fig: התמונה הכוללת

axes: רשימה של צירים (גרפים)




---
```python
🧰 df[df['trialtype'] == trial]
````

🔹 הסבר פשוט:

אנחנו אומרים לפייתון: "תביא לי רק את השורות מהטבלה שבהן סוג הניסוי הוא trial מסוים".

🎓 הסבר מקצועי:

סינון שורות באמצעות Boolean Masking:

מחזיר רק שורות שהן True בהתאמה.

נדרש כשאנחנו רוצים להציג או לנתח כל trialtype בנפרד (כמו ב־scatterplot או Pearson)



---
```python
🧠 VARS_TO_PRINT[mov_var]
````

🔹 הסבר פשוט:

במקום לכתוב כותרת גרף כמו movdist, נשתמש בשם יפה – לדוגמה: "Movement Distance".

🎓 הסבר מקצועי:

מילון שמבצע מיפוי משתנה → שם קריא

שימוש אסתטי בלבד (presentation layer)



---
```python
🧠 results[f'{mov_var}_{err_var}_{trial}'] = {...}
````

🔹 הסבר פשוט:

אנחנו שומרים את התוצאה (מתאם + p-value) בתוך תיבה שנוכל לחזור אליה מאוחר יותר.

🎓 הסבר מקצועי:

שימוש ב־dictionary עם מפתח דינמי

מחרוזת עם format – משלבת ערכים לתוך שם משתנה
```python
דוגמה: results['force_error_SelfPaced'] = {'correlation': 0.12, 'p_value': 0.038}
````


---
```python
🧪 if res['p_value'] < 0.05
````

🔹 הסבר פשוט:

בודקים האם הקשר שראינו בין תנועה לשגיאה באמת מובהק ולא יצא סתם במקרה.

🎓 הסבר מקצועי:

p-value מתחת ל־0.05 נחשב מובהקות סטטיסטית (רמת ביטחון של 95%)

הסינון מתבצע בלולאה:

```python
significant_pairs = [pair for pair, res in results.items() if res['p_value'] < 0.05]
````
יוצא מזה רשימה של כל השילובים המשמעותיים בלבד



---
```python
🎨 plt.scatter(..., c=trial_data['repduration'], cmap='viridis')
````
🔹 הסבר פשוט:

צובעים כל נקודה בגרף לפי כמה זמן לקחה התגובה – ככל שהיא ארוכה יותר, הצבע משתנה.

🎓 הסבר מקצועי:
```python
c=... – מכתיב צבע לפי משתנה מספרי

cmap='viridis' – מפה צבעים גרדיאנטית סטנדרטית

plt.colorbar(...) – מציג סרגל צבעים בצד שמראה מה כל צבע מייצג
````


---

🧱 טיפול בחריגות try...except

🔹 הסבר פשוט:

כמו חגורת בטיחות – אם משהו משתבש, נוכל להדפיס הודעה במקום שיקרוס הכל.

🎓 הסבר מקצועי:

try: עוטף את כל התהליך

תופסים חריגות נפוצות כמו:
```python
FileNotFoundError

EmptyDataError

ParserError
````

וגם חריגות כלליות (Exception)


זה חשוב מאוד בפרויקטים אמיתיים



---
```python
📥 main(DATA_PATH)
````

🔹 הסבר פשוט:

זה הקוד שמפעיל את הכול – הוא אומר: "יאללה, תתחיל לעבוד עם הקובץ הזה".

🎓 הסבר מקצועי:

קריאה לפונקציה הראשית (entry point)

מאפשר לרוץ כ־script באופן עצמאי

אם נרצה להפוך את זה בעתיד למודול או API – נוכל להוציא את הקריאה החוצה



---

✅ איך תסביר את זה למורה?

🎙️ כשאתה מציג את זה, תוכל לומר:

> "בניתי מערכת שלוקחת דאטה גולמי מניסוי תנועתי, בודקת שהמידע תקין, מנקה את החריגים, מציירת גרפים לפי סוג ניסוי ומשתנה, ואז מחשבת קשר סטטיסטי בין כל זוג של משתנה תנועה ושגיאה. אם הקשר מובהק, אני מנתח את ההשפעה של משך תגובה בעזרת גרפים תלת-ממדיים בצבע."



💡 ואז תוכל לפרט איך כל שלב בקוד ממומש – אתה שולט בזה עכשיו!
